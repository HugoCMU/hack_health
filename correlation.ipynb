{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Hackathon: Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "ROOT_DIR = Path.cwd()\n",
    "GYRO_CSV = ROOT_DIR / 'Anand-history.csv'\n",
    "\n",
    "# Read data from CSV\n",
    "gyro = pd.read_csv(GYRO_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix using Seaborn\n",
    "corrmat = gyro.corr() #weight_data.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Next Steps\n",
    "\n",
    "Try to predict future health information\n",
    "\n",
    "Sources:\n",
    " - [1] https://github.com/floydhub/time-sequence-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Params\n",
    "NUM_EPOCH = 8\n",
    "LR = 0.01\n",
    "\n",
    "# Columns used for prediction and columns to be predicted\n",
    "IN_COL = ['steps', 'commits']\n",
    "OUT_COL = ['weight']\n",
    "\n",
    "# CUDA?\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# Model\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 1)\n",
    "        if CUDA:\n",
    "            self.lstm1, self.lstm2 = self.lstm1.cuda(), self.lstm2.cuda()\n",
    "\n",
    "    def forward(self, input, future = 0):\n",
    "        outputs = []\n",
    "        h_t = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "        h_t2 = Variable(torch.zeros(input.size(0), 1).double(), requires_grad=False)\n",
    "        c_t2 = Variable(torch.zeros(input.size(0), 1).double(), requires_grad=False)\n",
    "        if CUDA:\n",
    "            h_t, c_t, h_t2, c_t2 = h_t.cuda(), c_t.cuda(), h_t2.cuda(), c_t2.cuda()\n",
    "\n",
    "        # Iterate over columns\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            outputs += [h_t2]\n",
    "\n",
    "        # Begin with the test input and continue for steps in range(future) predictions\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(h_t2, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            outputs += [h_t2]\n",
    "        # Compact the list of predictions\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# set ramdom seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Input and target data are from csv\n",
    "input_data = gyro[IN_COL].as_matrix()\n",
    "target_data = gyro[OUT_COL].as_matrix()\n",
    "predict_from = 200 # Use data before this to train, predict points after this\n",
    "\n",
    "# Train data (from index 0 to predict_from)\n",
    "input = Variable(torch.from_numpy(input_data[predict_from:]), requires_grad=False)\n",
    "target = Variable(torch.from_numpy(target_data[predict_from:]), requires_grad=False)\n",
    "if CUDA:\n",
    "    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "# Test Data (from index predict_from onwards)\n",
    "test_input = Variable(torch.from_numpy(input_data[:predict_from]), requires_grad=False)\n",
    "test_target = Variable(torch.from_numpy(target_data[:predict_from]), requires_grad=False)\n",
    "if CUDA:\n",
    "    test_input, test_target = test_input.cuda(), test_target.cuda()\n",
    "\n",
    "# build the model\n",
    "seq = Sequence()\n",
    "seq.double()\n",
    "criterion = nn.MSELoss()\n",
    "if CUDA:\n",
    "    criterion.cuda()\n",
    "\n",
    "# use LBFGS as optimizer since we can load the whole data to train\n",
    "optimizer = optim.LBFGS(seq.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Training\n",
    "for i in range(NUM_EPOCH):\n",
    "    print('STEP: ', i)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(input)\n",
    "        loss = criterion(out, target)\n",
    "        print('loss:', loss.data.cpu().numpy()[0])\n",
    "        loss.backward()\n",
    "        return loss.float()\n",
    "    optimizer.step(closure)\n",
    "    # begin to predict\n",
    "    future = 1000\n",
    "    pred = seq(test_input, future = future)\n",
    "    loss = criterion(pred[:, :-future], test_target)\n",
    "    print('test loss:', loss.data.cpu().numpy()[0])\n",
    "    y = pred.data.cpu().numpy()\n",
    "#     # draw the result\n",
    "#     plt.figure(figsize=(30,10))\n",
    "#     plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "#     plt.xlabel('x', fontsize=20)\n",
    "#     plt.ylabel('y', fontsize=20)\n",
    "#     plt.xticks(fontsize=20)\n",
    "#     plt.yticks(fontsize=20)\n",
    "#     def draw(yi, color):\n",
    "#         plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
    "#         plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
    "#     draw(y[0], 'r')\n",
    "#     draw(y[1], 'g')\n",
    "#     draw(y[2], 'b')\n",
    "#     plt.close()\n",
    "\n",
    "# Do checkpointing - Is saved in outf\n",
    "torch.save(seq.state_dict(), 'saved_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
