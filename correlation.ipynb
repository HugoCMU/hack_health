{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Hackathon: Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "ROOT_DIR = Path.cwd()\n",
    "GYRO_CSV = ROOT_DIR / 'Anand-history.csv'\n",
    "\n",
    "# Read data from CSV\n",
    "gyro = pd.read_csv(GYRO_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix using Seaborn\n",
    "corrmat = gyro.corr() #weight_data.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Next Steps\n",
    "\n",
    "Try to predict future health information by using the sequential nature of the data to train an LSTM.\n",
    "\n",
    "Sources:\n",
    " - [1] https://github.com/floydhub/time-sequence-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Params\n",
    "NUM_EPOCH = 8\n",
    "LR = 0.01\n",
    "HIDDEN_DIM = 12 # Dimension of hidden state in LSTM\n",
    "\n",
    "# Columns used for prediction / to be predicted\n",
    "PRED = ['weight']\n",
    "\n",
    "# CUDA?\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# Model\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self, hidden_dim=1):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.hd = hidden_dim\n",
    "        self.lstm1 = nn.LSTMCell(1, hidden_dim)\n",
    "        self.lstm2 = nn.LSTMCell(hidden_dim, 1)\n",
    "        if CUDA:\n",
    "            self.lstm1, self.lstm2 = self.lstm1.cuda(), self.lstm2.cuda()\n",
    "\n",
    "    def forward(self, input, future=0):\n",
    "        outputs = []\n",
    "        h_t = Variable(torch.zeros(input.size(0), self.hd).double(), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(input.size(0), self.hd).double(), requires_grad=False)\n",
    "        h_t2 = Variable(torch.zeros(input.size(0), 1).double(), requires_grad=False)\n",
    "        c_t2 = Variable(torch.zeros(input.size(0), 1).double(), requires_grad=False)\n",
    "        if CUDA:\n",
    "            h_t, c_t, h_t2, c_t2 = h_t.cuda(), c_t.cuda(), h_t2.cuda(), c_t2.cuda()\n",
    "\n",
    "        # Iterate over columns\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            outputs += [h_t2]\n",
    "\n",
    "        # Begin with the test input and continue for steps in range(future) predictions\n",
    "        for i in range(future):  # if we should predict the future\n",
    "            h_t, c_t = self.lstm1(h_t2, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            outputs += [h_t2]\n",
    "        # Compact the list of predictions\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# set ramdom seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Input and target data are from csv\n",
    "data = gyro[PRED].as_matrix()\n",
    "data = (data-data.mean())/data.std() # Normalize\n",
    "predict_from = 200  # Use data before this to train, after to test\n",
    "\n",
    "# Train data (from index 0 to predict_from)\n",
    "input = Variable(torch.from_numpy(data[predict_from:, :-1]), requires_grad=False)\n",
    "target = Variable(torch.from_numpy(data[predict_from:, 1:]), requires_grad=False)\n",
    "if CUDA:\n",
    "    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "# Test Data (from index predict_from onwards)\n",
    "test_input = Variable(torch.from_numpy(data[:predict_from, :-1]), requires_grad=False)\n",
    "test_target = Variable(torch.from_numpy(data[:predict_from, 1:]), requires_grad=False)\n",
    "if CUDA:\n",
    "    test_input, test_target = test_input.cuda(), test_target.cuda()\n",
    "\n",
    "# Convert input data to double\n",
    "input = input.double()\n",
    "target = target.double()\n",
    "test_input = test_input.double()\n",
    "test_target = test_target.double()\n",
    "\n",
    "# build the model\n",
    "seq = Sequence(hidden_dim=HIDDEN_DIM)\n",
    "seq.double()\n",
    "criterion = nn.MSELoss()\n",
    "if CUDA:\n",
    "    criterion.cuda()\n",
    "\n",
    "# use LBFGS as optimizer since we can load the whole data to train\n",
    "optimizer = optim.LBFGS(seq.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Training\n",
    "for i in range(NUM_EPOCH):\n",
    "    print('STEP: ', i)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(input)\n",
    "        loss = criterion(out, target)\n",
    "#         print('loss:', loss.data.cpu().numpy()[0])\n",
    "        loss.backward()\n",
    "        return loss.float()\n",
    "    optimizer.step(closure)\n",
    "    # begin to predict\n",
    "    pred = seq(test_input, future=predict_from)\n",
    "    loss = criterion(pred[:, :-predict_from], test_target)\n",
    "    print('test loss:', loss.data.cpu().numpy()[0])\n",
    "    y = pred.data.cpu().numpy()\n",
    "    # draw the result\n",
    "    plt.figure()\n",
    "    plt.title('Predict future values for %s' % ','.join(PRED), fontsize=30)\n",
    "    plt.xlabel('days', fontsize=20)\n",
    "    plt.ylabel(','.join(PRED), fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    def draw(yi, color):\n",
    "        plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
    "        plt.plot(np.arange(input.size(1), input.size(1) + predict_from), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    plt.close()\n",
    "\n",
    "# Do checkpointing - Is saved in outf\n",
    "torch.save(seq.state_dict(), 'saved_model.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
